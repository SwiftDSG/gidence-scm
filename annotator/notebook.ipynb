{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-Labeler Training - Single Model (All PPE Classes)\n",
    "\n",
    "**Project:** Safety Compliance Monitoring (SCM)\n",
    "\n",
    "**Date:** January 2026\n",
    "\n",
    "**Objective:** Train ONE YOLOv8 model for auto-labeling purposes\n",
    "- ALL 17 SH17 PPE classes in single model\n",
    "- Used for generating pre-annotations\n",
    "- Speeds up supplement dataset annotation\n",
    "- Future-proof: Can use additional classes later if needed\n",
    "\n",
    "**Note:** This is the AUTO-LABELING model, not the final deployment models!\n",
    "\n",
    "**Classes (17 total):**\n",
    "- Core 9: hardhat, vest, shoes, gloves, glasses, facemask, faceguard, earmuffs, safetysuit\n",
    "- Additional 8: (boots, safety-harness, goggles, respirator, apron, welding-mask, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install ultralytics roboflow opencv-python matplotlib seaborn pandas\n",
    "\n",
    "# Verify installation\n",
    "import ultralytics\n",
    "print(f\"Ultralytics version: {ultralytics.__version__}\")\n",
    "\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up directories\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "base_dir = Path.home() / 'optense' / 'scm'\n",
    "models_dir = base_dir / 'models'\n",
    "datasets_dir = base_dir / 'datasets'\n",
    "results_dir = base_dir / 'training_results' / 'auto_labeler'\n",
    "\n",
    "for dir_path in [models_dir, datasets_dir, results_dir]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"‚úì Base directory: {base_dir}\")\n",
    "print(f\"‚úì Results will be saved to: {results_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download SH17 Dataset from Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "\n",
    "# ============================================\n",
    "# CONFIGURATION - UPDATE THESE VALUES\n",
    "# ============================================\n",
    "\n",
    "ROBOFLOW_API_KEY = \"Xp2CBnbQfijsteBmE2Op\"  # From: https://app.roboflow.com/settings/api\n",
    "WORKSPACE_NAME = \"optense\"\n",
    "PROJECT_NAME = \"scm-person-detector\"\n",
    "VERSION_NUMBER = 3\n",
    "\n",
    "# ============================================\n",
    "\n",
    "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
    "print(\"‚úì Roboflow initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "print(\"Downloading SH17 dataset (all 17 PPE classes)...\")\n",
    "\n",
    "project = rf.workspace(WORKSPACE_NAME).project(PROJECT_NAME)\n",
    "dataset = project.version(VERSION_NUMBER).download(\n",
    "    \"yolov8\",\n",
    "    location=str(datasets_dir / \"sh17_full\")\n",
    ")\n",
    "\n",
    "print(f\"‚úì Dataset downloaded to: {dataset.location}\")\n",
    "\n",
    "data_yaml = Path(dataset.location) / \"data.yaml\"\n",
    "print(f\"‚úì data.yaml found: {data_yaml.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data.yaml\n",
    "with open(data_yaml, 'r') as f:\n",
    "    data = yaml.safe_load(f)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SH17 DATASET - AUTO-LABELER TRAINING\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Number of classes: {data['nc']}\")\n",
    "print(f\"Class names: {data['names']}\")\n",
    "\n",
    "# Count images\n",
    "dataset_root = Path(data_yaml).parent\n",
    "train_images = list((dataset_root / data['train']).glob('*.jpg')) + \\\n",
    "               list((dataset_root / data['train']).glob('*.png'))\n",
    "val_images = list((dataset_root / data['val']).glob('*.jpg')) + \\\n",
    "             list((dataset_root / data['val']).glob('*.png'))\n",
    "\n",
    "print(f\"\\nDataset size:\")\n",
    "print(f\"  Train images: {len(train_images)}\")\n",
    "print(f\"  Val images: {len(val_images)}\")\n",
    "print(f\"  Total: {len(train_images) + len(val_images)}\")\n",
    "\n",
    "# Count annotations per class\n",
    "train_labels_dir = dataset_root / data['train'].replace('images', 'labels')\n",
    "class_counts = Counter()\n",
    "\n",
    "for label_file in train_labels_dir.glob('*.txt'):\n",
    "    with open(label_file, 'r') as f:\n",
    "        for line in f:\n",
    "            class_id = int(line.split()[0])\n",
    "            class_counts[class_id] += 1\n",
    "\n",
    "print(f\"\\nClass distribution:\")\n",
    "for class_id, count in sorted(class_counts.items()):\n",
    "    class_name = data['names'][class_id]\n",
    "    print(f\"  {class_name:15s}: {count:5d} annotations\")\n",
    "\n",
    "total_annotations = sum(class_counts.values())\n",
    "print(f\"\\nTotal annotations: {total_annotations}\")\n",
    "\n",
    "# Calculate imbalance ratio\n",
    "max_count = max(class_counts.values())\n",
    "min_count = min(class_counts.values())\n",
    "print(f\"Imbalance ratio: {max_count/min_count:.1f}:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "class_names = [data['names'][i] for i in sorted(class_counts.keys())]\n",
    "counts = [class_counts[i] for i in sorted(class_counts.keys())]\n",
    "\n",
    "colors = ['#ff6b6b' if c < 500 else '#4ecdc4' if c < 1500 else '#95e1d3' \n",
    "          for c in counts]\n",
    "\n",
    "plt.bar(class_names, counts, color=colors)\n",
    "plt.xlabel('Class', fontsize=12)\n",
    "plt.ylabel('Number of Annotations', fontsize=12)\n",
    "plt.title('SH17 Dataset - Class Distribution', fontsize=14)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='#ff6b6b', label='Low (<500)'),\n",
    "    Patch(facecolor='#4ecdc4', label='Medium (500-1500)'),\n",
    "    Patch(facecolor='#95e1d3', label='High (>1500)')\n",
    "]\n",
    "plt.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration for auto-labeler\n",
    "\n",
    "EPOCHS = 100  # Can reduce to 50 if time is critical\n",
    "BATCH_SIZE = 16  # Adjust based on GPU memory\n",
    "IMAGE_SIZE = 640\n",
    "PATIENCE = 20\n",
    "\n",
    "training_config = {\n",
    "    'data': str(data_yaml),\n",
    "    'epochs': EPOCHS,\n",
    "    'batch': BATCH_SIZE,\n",
    "    'imgsz': IMAGE_SIZE,\n",
    "    'patience': PATIENCE,\n",
    "    'save': True,\n",
    "    'save_period': 10,\n",
    "    'device': 0 if torch.cuda.is_available() else 'cpu',\n",
    "    'workers': 8,\n",
    "    'project': str(results_dir),\n",
    "    'name': 'yolov8n_auto_labeler',\n",
    "    'exist_ok': True,\n",
    "    'pretrained': True,\n",
    "    'optimizer': 'AdamW',\n",
    "    'verbose': True,\n",
    "    'seed': 42,\n",
    "    'cos_lr': True,\n",
    "    'close_mosaic': 10,\n",
    "    'resume': False,\n",
    "    'amp': True,\n",
    "    \n",
    "    # Learning rates\n",
    "    'lr0': 0.01,\n",
    "    'lrf': 0.01,\n",
    "    'momentum': 0.937,\n",
    "    'weight_decay': 0.0005,\n",
    "    'warmup_epochs': 3.0,\n",
    "    'warmup_momentum': 0.8,\n",
    "    'warmup_bias_lr': 0.1,\n",
    "    \n",
    "    # Loss weights (adjust these for class imbalance)\n",
    "    'box': 7.5,      # Box loss weight\n",
    "    'cls': 0.5,      # Classification loss weight\n",
    "    'dfl': 1.5,      # DFL loss weight\n",
    "    \n",
    "    # Augmentation (moderate-aggressive for 17 classes)\n",
    "    'hsv_h': 0.018,\n",
    "    'hsv_s': 0.7,\n",
    "    'hsv_v': 0.4,\n",
    "    'degrees': 12.0,\n",
    "    'translate': 0.15,\n",
    "    'scale': 0.6,\n",
    "    'shear': 0.0,\n",
    "    'perspective': 0.0,\n",
    "    'flipud': 0.0,\n",
    "    'fliplr': 0.5,\n",
    "    'mosaic': 1.0,\n",
    "    'mixup': 0.2,\n",
    "    'copy_paste': 0.15,\n",
    "    \n",
    "    # Validation\n",
    "    'plots': True,\n",
    "    'val': True,\n",
    "}\n",
    "\n",
    "print(\"‚úì Training configuration ready\")\n",
    "print(f\"  Device: {training_config['device']}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Image size: {IMAGE_SIZE}√ó{IMAGE_SIZE}\")\n",
    "print(\"\\nNote: YOLOv8 handles class imbalance automatically during training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Auto-Labeler Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TRAINING AUTO-LABELER MODEL\")\n",
    "print(\"=\"*60)\n",
    "print(\"Purpose: Generate pre-annotations for supplement dataset\")\n",
    "print(\"Classes: All 17 PPE types (including future-use classes)\")\n",
    "print(\"\\nStarting training...\")\n",
    "print(\"Expected duration: 2-4 hours\")\n",
    "print(\"You can let this run overnight!\")\n",
    "print(\"\")\n",
    "\n",
    "# Initialize model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Train\n",
    "results = model.train(**training_config)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úì TRAINING COMPLETE!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating auto-labeler on validation set...\\n\")\n",
    "metrics = model.val()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"AUTO-LABELER MODEL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"Recall: {metrics.box.mr:.4f}\")\n",
    "\n",
    "print(\"\\nPer-class mAP50:\")\n",
    "for i, class_name in enumerate(data['names']):\n",
    "    if hasattr(metrics.box, 'maps') and i < len(metrics.box.maps):\n",
    "        class_map = metrics.box.maps[i]\n",
    "        status = \"‚úì\" if class_map > 0.6 else \"‚ö†Ô∏è\" if class_map > 0.4 else \"‚ùå\"\n",
    "        print(f\"  {status} {class_name:15s}: {class_map:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NOTE: This model is for AUTO-LABELING, not deployment\")\n",
    "print(\"Lower accuracy is acceptable - human will verify!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Find results directory\n",
    "run_dirs = sorted(results_dir.glob('*'), key=os.path.getmtime, reverse=True)\n",
    "if run_dirs:\n",
    "    latest_run = run_dirs[0]\n",
    "    print(f\"Loading results from: {latest_run}\\n\")\n",
    "    \n",
    "    # Display key plots\n",
    "    plot_files = ['results.png', 'confusion_matrix.png', 'val_batch0_pred.jpg']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "    fig.suptitle('Auto-Labeler Training Results', fontsize=16)\n",
    "    \n",
    "    for idx, plot_file in enumerate(plot_files):\n",
    "        plot_path = latest_run / plot_file\n",
    "        if plot_path.exists():\n",
    "            img = Image.open(plot_path)\n",
    "            axes[idx].imshow(img)\n",
    "            axes[idx].axis('off')\n",
    "            title = plot_file.replace('.png', '').replace('.jpg', '').replace('_', ' ').title()\n",
    "            axes[idx].set_title(title)\n",
    "        else:\n",
    "            axes[idx].text(0.5, 0.5, f'{plot_file} not found', \n",
    "                          ha='center', va='center')\n",
    "            axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No training results found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test on Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "\n",
    "# Get random validation images\n",
    "test_images = random.sample(val_images, min(6, len(val_images)))\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('Auto-Labeler Predictions on Validation Set', fontsize=16)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, img_path in enumerate(test_images):\n",
    "    # Run prediction\n",
    "    results = model.predict(source=str(img_path), conf=0.25, verbose=False)\n",
    "    \n",
    "    # Get annotated image\n",
    "    annotated = results[0].plot()\n",
    "    annotated = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    axes[idx].imshow(annotated)\n",
    "    axes[idx].axis('off')\n",
    "    axes[idx].set_title(f\"{Path(img_path).name}\\n{len(results[0].boxes)} detections\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Model for Auto-Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best weights\n",
    "best_weights = list(results_dir.glob('**/weights/best.pt'))[0]\n",
    "print(f\"Best weights: {best_weights}\")\n",
    "\n",
    "# Copy to organized location\n",
    "import shutil\n",
    "\n",
    "auto_labeler_dir = models_dir / 'auto_labeler'\n",
    "auto_labeler_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "auto_labeler_model = auto_labeler_dir / 'yolov8n_auto_labeler.pt'\n",
    "shutil.copy(best_weights, auto_labeler_model)\n",
    "\n",
    "print(f\"\\n‚úì Auto-labeler model saved to: {auto_labeler_model}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"READY FOR AUTO-LABELING!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Use this model to pre-annotate supplement images\")\n",
    "print(\"2. Human reviews and corrects annotations\")\n",
    "print(\"3. Merge corrected data with SH17\")\n",
    "print(\"4. Train specialized Model A and Model B for deployment\")\n",
    "print(\"\")\n",
    "print(f\"Auto-labeler ready at: {auto_labeler_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Create Auto-Labeling Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save auto-labeling script for easy use\n",
    "\n",
    "auto_label_script = base_dir / 'tools' / 'auto_label.py'\n",
    "auto_label_script.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "script_content = f'''#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Auto-Labeler Script\n",
    "Uses trained model to generate pre-annotations for manual review.\n",
    "\n",
    "Usage:\n",
    "    python auto_label.py --input unlabeled_images/ --output pre_annotated/\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "import shutil\n",
    "\n",
    "# Model path\n",
    "MODEL_PATH = \"{auto_labeler_model}\"\n",
    "\n",
    "def auto_label(input_dir, output_dir, conf_threshold=0.25):\n",
    "    \"\"\"Auto-label images using trained model.\"\"\"\n",
    "    \n",
    "    print(f\"Loading model: {{MODEL_PATH}}\")\n",
    "    model = YOLO(MODEL_PATH)\n",
    "    \n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    \n",
    "    (output_dir / 'images').mkdir(parents=True, exist_ok=True)\n",
    "    (output_dir / 'labels').mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Get all images\n",
    "    image_files = []\n",
    "    for ext in ['*.jpg', '*.jpeg', '*.png']:\n",
    "        image_files.extend(list(input_dir.glob(ext)))\n",
    "    \n",
    "    print(f\"Found {{len(image_files)}} images to process\")\n",
    "    \n",
    "    stats = {{'processed': 0, 'with_detections': 0, 'total_detections': 0}}\n",
    "    \n",
    "    for i, img_path in enumerate(image_files, 1):\n",
    "        results = model.predict(source=str(img_path), conf=conf_threshold, verbose=False)\n",
    "        result = results[0]\n",
    "        \n",
    "        if result.boxes is not None and len(result.boxes) > 0:\n",
    "            stats['with_detections'] += 1\n",
    "            stats['total_detections'] += len(result.boxes)\n",
    "            \n",
    "            # Copy image\n",
    "            shutil.copy(img_path, output_dir / 'images' / img_path.name)\n",
    "            \n",
    "            # Save annotations in YOLO format\n",
    "            label_file = output_dir / 'labels' / f\"{{img_path.stem}}.txt\"\n",
    "            \n",
    "            with open(label_file, 'w') as f:\n",
    "                for box in result.boxes:\n",
    "                    # Get box in YOLO format\n",
    "                    class_id = int(box.cls[0])\n",
    "                    x_center, y_center, width, height = box.xywhn[0].tolist()\n",
    "                    f.write(f\"{{class_id}} {{x_center:.6f}} {{y_center:.6f}} {{width:.6f}} {{height:.6f}}\\\\n\")\n",
    "        \n",
    "        stats['processed'] += 1\n",
    "        if i % 50 == 0:\n",
    "            print(f\"  Processed: {{i}}/{{len(image_files)}}\")\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*60)\n",
    "    print(\"AUTO-LABELING COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total images: {{stats['processed']}}\")\n",
    "    print(f\"Images with detections: {{stats['with_detections']}}\")\n",
    "    print(f\"Total detections: {{stats['total_detections']}}\")\n",
    "    if stats['with_detections'] > 0:\n",
    "        print(f\"Avg detections/image: {{stats['total_detections']/stats['with_detections']:.1f}}\")\n",
    "    print(f\"\\\\nOutput: {{output_dir}}\")\n",
    "    print(\"\\\\n‚ö†Ô∏è  IMPORTANT: Review and verify all annotations!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Auto-label PPE images')\n",
    "    parser.add_argument('--input', required=True, help='Input directory with unlabeled images')\n",
    "    parser.add_argument('--output', required=True, help='Output directory for annotated images')\n",
    "    parser.add_argument('--conf', type=float, default=0.25, help='Confidence threshold')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    auto_label(args.input, args.output, args.conf)\n",
    "'''\n",
    "\n",
    "with open(auto_label_script, 'w') as f:\n",
    "    f.write(script_content)\n",
    "\n",
    "# Make executable\n",
    "import stat\n",
    "auto_label_script.chmod(auto_label_script.stat().st_mode | stat.S_IEXEC)\n",
    "\n",
    "print(f\"‚úì Auto-labeling script saved to: {auto_label_script}\")\n",
    "print(\"\\nUsage:\")\n",
    "print(f\"  python {auto_label_script} --input unlabeled/ --output annotated/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"AUTO-LABELER TRAINING COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìä MODEL PERFORMANCE:\")\n",
    "print(f\"   mAP50: {metrics.box.map50:.4f}\")\n",
    "print(f\"   mAP50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"   Classes: {', '.join(data['names'])}\")\n",
    "\n",
    "print(\"\\nüìÅ OUTPUT FILES:\")\n",
    "print(f\"   Model: {auto_labeler_model}\")\n",
    "print(f\"   Script: {auto_label_script}\")\n",
    "print(f\"   Results: {results_dir}\")\n",
    "\n",
    "print(\"\\n‚úÖ NEXT STEPS:\")\n",
    "print(\"   1. Run auto-labeling on supplement images:\")\n",
    "print(f\"      python {auto_label_script} --input supplements/ --output pre_annotated/\")\n",
    "print(\"\")\n",
    "print(\"   2. Review and correct annotations in Roboflow/CVAT\")\n",
    "print(\"\")\n",
    "print(\"   3. Merge corrected data with SH17\")\n",
    "print(\"\")\n",
    "print(\"   4. Train final Model A (common PPE) and Model B (rare PPE)\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
