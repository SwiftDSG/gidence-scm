{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Deployment Model Training - SCM Project\n",
    "\n",
    "**Project:** Safety Compliance Monitoring (SCM)\n",
    "\n",
    "**Date:** January 2026\n",
    "\n",
    "**Objective:** Train final 17-class deployment model for real-time PPE detection\n",
    "\n",
    "**Approach:**\n",
    "- Train on high-quality data from Model Zoo auto-labeling + SH17 base dataset\n",
    "- Use best practices from SH17 paper (70.9% mAP benchmark)\n",
    "- Optimize for edge deployment (Hailo-8 on Raspberry Pi 5)\n",
    "- Target: 65-75% mAP50 overall\n",
    "\n",
    "**Hardware Target:**\n",
    "- Hailo-8 AI Accelerator (26 TOPS)\n",
    "- Multi-camera support (4 cameras simultaneously)\n",
    "- Real-time inference: 12-15 FPS per camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install ultralytics roboflow opencv-python matplotlib seaborn pandas pillow pyyaml\n",
    "\n",
    "import ultralytics\n",
    "print(f\"Ultralytics version: {ultralytics.__version__}\")\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import yaml\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up directories\n",
    "base_dir = Path.home() / 'optense' / 'scm'\n",
    "dataset_dir = base_dir / 'datasets' / 'final_merged'\n",
    "models_dir = base_dir / 'models' / 'deployment'\n",
    "results_dir = base_dir / 'training_results' / 'deployment'\n",
    "\n",
    "for dir_path in [models_dir, results_dir]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"âœ“ Base directory: {base_dir}\")\n",
    "print(f\"âœ“ Dataset directory: {dataset_dir}\")\n",
    "print(f\"âœ“ Models will be saved to: {models_dir}\")\n",
    "print(f\"âœ“ Training results: {results_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Dataset from Roboflow\n",
    "\n",
    "Download your final merged dataset (SH17 base + auto-labeled supplements) from Roboflow.\n",
    "\n",
    "**Requirements:**\n",
    "- Roboflow API key (get from: https://app.roboflow.com/settings/api)\n",
    "- Your merged dataset project name\n",
    "- Dataset version number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ROBOFLOW CONFIGURATION\n",
    "# ============================================\n",
    "\n",
    "ROBOFLOW_API_KEY = \"Xp2CBnbQfijsteBmE2Op\"  # Get from: https://app.roboflow.com/settings/api\n",
    "WORKSPACE_NAME = \"optense\"       # Your Roboflow workspace name\n",
    "PROJECT_NAME = \"scm-v1\"         # Your merged dataset project name\n",
    "VERSION_NUMBER = 2                      # Dataset version number\n",
    "\n",
    "print(\"Roboflow Configuration:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Workspace: {WORKSPACE_NAME}\")\n",
    "print(f\"Project: {PROJECT_NAME}\")\n",
    "print(f\"Version: {VERSION_NUMBER}\")\n",
    "print(f\"API Key: {'*' * (len(ROBOFLOW_API_KEY) - 4) + ROBOFLOW_API_KEY[-4:] if len(ROBOFLOW_API_KEY) > 4 else '(not set)'}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset from Roboflow\n",
    "from roboflow import Roboflow\n",
    "\n",
    "if ROBOFLOW_API_KEY == \"YOUR_API_KEY_HERE\":\n",
    "    print(\"âš ï¸  Please set your Roboflow API key in the cell above!\")\n",
    "    print(\"\\nSteps:\")\n",
    "    print(\"1. Go to: https://app.roboflow.com/settings/api\")\n",
    "    print(\"2. Copy your Private API Key\")\n",
    "    print(\"3. Paste it in ROBOFLOW_API_KEY above\")\n",
    "    print(\"4. Update WORKSPACE_NAME, PROJECT_NAME, and VERSION_NUMBER\")\n",
    "    print(\"5. Run this cell again\")\n",
    "else:\n",
    "    try:\n",
    "        print(\"Downloading dataset from Roboflow...\")\n",
    "        print(\"This may take several minutes depending on dataset size.\\n\")\n",
    "        \n",
    "        # Initialize Roboflow\n",
    "        rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
    "        print(\"âœ“ Roboflow initialized\")\n",
    "        \n",
    "        # Get project\n",
    "        project = rf.workspace(WORKSPACE_NAME).project(PROJECT_NAME)\n",
    "        print(f\"âœ“ Project '{PROJECT_NAME}' accessed\")\n",
    "        \n",
    "        # Download dataset\n",
    "        print(f\"\\nDownloading version {VERSION_NUMBER}...\")\n",
    "        dataset = project.version(VERSION_NUMBER).download(\n",
    "            'yolov8',\n",
    "            location=str(dataset_dir)\n",
    "        )\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"âœ“ DOWNLOAD COMPLETE!\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"Dataset location: {dataset.location}\")\n",
    "        \n",
    "        # Update dataset_dir to actual location\n",
    "        dataset_dir = Path(dataset.location)\n",
    "        data_yaml_path = dataset_dir / 'data.yaml'\n",
    "        \n",
    "        # Verify download\n",
    "        if data_yaml_path.exists():\n",
    "            with open(data_yaml_path, 'r') as f:\n",
    "                config = yaml.safe_load(f)\n",
    "            \n",
    "            print(f\"\\nâœ“ Dataset verified:\")\n",
    "            print(f\"  Classes: {config['nc']}\")\n",
    "            \n",
    "            # Handle both list and dict formats for class names\n",
    "            if isinstance(config['names'], list):\n",
    "                class_names = config['names']\n",
    "            else:\n",
    "                class_names = list((config['names'] if isinstance(config['names'], list) else list(config['names'].values())))\n",
    "            \n",
    "            print(f\"  Class names: {class_names}\")\n",
    "            \n",
    "            # Count images\n",
    "            train_images = list((dataset_dir / 'train' / 'images').glob('*'))\n",
    "            val_images = list((dataset_dir / 'val' / 'images').glob('*'))\n",
    "            \n",
    "            print(f\"\\n  Train images: {len(train_images)}\")\n",
    "            print(f\"  Val images: {len(val_images)}\")\n",
    "            print(f\"  Total: {len(train_images) + len(val_images)}\")\n",
    "            \n",
    "            print(\"\\n\" + \"=\" * 70)\n",
    "            print(\"âœ“ Ready to proceed with training!\")\n",
    "            print(\"=\" * 70)\n",
    "        else:\n",
    "            print(\"\\nâš ï¸  Warning: data.yaml not found after download\")\n",
    "            print(\"   Please check the download location.\")\n",
    "    \n",
    "    except ImportError:\n",
    "        print(\"âŒ Error: roboflow package not installed\")\n",
    "        print(\"   Run: !pip install roboflow\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Error downloading dataset: {e}\")\n",
    "        print(\"\\nTroubleshooting:\")\n",
    "        print(\"  1. Check API key is correct (should start with your workspace name)\")\n",
    "        print(\"  2. Verify workspace name matches your Roboflow workspace\")\n",
    "        print(\"  3. Confirm project name is correct (check in Roboflow)\")\n",
    "        print(\"  4. Verify version number exists (check project versions)\")\n",
    "        print(\"  5. Ensure you have access permissions to the project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset configuration\n",
    "data_yaml_path = dataset_dir / 'data.yaml'\n",
    "\n",
    "if not data_yaml_path.exists():\n",
    "    print(f\"âŒ ERROR: data.yaml not found at {data_yaml_path}\")\n",
    "    print(\"Please ensure your merged dataset is ready!\")\n",
    "else:\n",
    "    with open(data_yaml_path, 'r') as f:\n",
    "        data_config = yaml.safe_load(f)\n",
    "    \n",
    "    print(\"Dataset Configuration:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Number of classes: {data_config['nc']}\")\n",
    "    print(f\"\\nClass names:\")\n",
    "    for idx, name in data_config['names'].items():\n",
    "        print(f\"  {idx:2d}: {name}\")\n",
    "    \n",
    "    print(f\"\\nTrain path: {data_config['train']}\")\n",
    "    print(f\"Val path: {data_config['val']}\")\n",
    "    if 'test' in data_config:\n",
    "        print(f\"Test path: {data_config['test']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count images and annotations\n",
    "def count_dataset_statistics(dataset_root, split='train'):\n",
    "    \"\"\"\n",
    "    Count images and analyze class distribution.\n",
    "    \"\"\"\n",
    "    \n",
    "    images_dir = dataset_root / split / 'images'\n",
    "    labels_dir = dataset_root / split / 'labels'\n",
    "    \n",
    "    # Count images\n",
    "    image_files = list(images_dir.glob('*.jpg')) + list(images_dir.glob('*.png'))\n",
    "    \n",
    "    # Count annotations per class\n",
    "    class_counts = {}\n",
    "    total_annotations = 0\n",
    "    images_with_annotations = 0\n",
    "    \n",
    "    for img_file in image_files:\n",
    "        label_file = labels_dir / f\"{img_file.stem}.txt\"\n",
    "        \n",
    "        if label_file.exists():\n",
    "            with open(label_file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            if lines:\n",
    "                images_with_annotations += 1\n",
    "                \n",
    "                for line in lines:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) >= 5:\n",
    "                        class_id = int(parts[0])\n",
    "                        class_counts[class_id] = class_counts.get(class_id, 0) + 1\n",
    "                        total_annotations += 1\n",
    "    \n",
    "    return {\n",
    "        'total_images': len(image_files),\n",
    "        'images_with_annotations': images_with_annotations,\n",
    "        'total_annotations': total_annotations,\n",
    "        'class_counts': class_counts\n",
    "    }\n",
    "\n",
    "# Analyze train and val splits\n",
    "print(\"\\nDataset Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "train_stats = count_dataset_statistics(dataset_dir, 'train')\n",
    "val_stats = count_dataset_statistics(dataset_dir, 'val')\n",
    "\n",
    "print(f\"\\nTrain split:\")\n",
    "print(f\"  Total images: {train_stats['total_images']}\")\n",
    "print(f\"  Images with annotations: {train_stats['images_with_annotations']}\")\n",
    "print(f\"  Total annotations: {train_stats['total_annotations']}\")\n",
    "print(f\"  Avg annotations per image: {train_stats['total_annotations'] / train_stats['images_with_annotations']:.2f}\")\n",
    "\n",
    "print(f\"\\nValidation split:\")\n",
    "print(f\"  Total images: {val_stats['total_images']}\")\n",
    "print(f\"  Images with annotations: {val_stats['images_with_annotations']}\")\n",
    "print(f\"  Total annotations: {val_stats['total_annotations']}\")\n",
    "print(f\"  Avg annotations per image: {val_stats['total_annotations'] / val_stats['images_with_annotations']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "def visualize_class_distribution(train_stats, val_stats, class_names):\n",
    "    \"\"\"\n",
    "    Create visualization of class distribution.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare data\n",
    "    classes = []\n",
    "    train_counts = []\n",
    "    val_counts = []\n",
    "    \n",
    "    # Handle both list and dict formats\n",
    "    if isinstance(class_names, list):\n",
    "        class_ids = range(len(class_names))\n",
    "    else:\n",
    "        class_ids = sorted(class_names.keys())\n",
    "    \n",
    "    for class_id in class_ids:\n",
    "        class_name = class_names[class_id] if isinstance(class_names, (list, dict)) else str(class_id)\n",
    "        classes.append(class_name)\n",
    "        train_counts.append(train_stats['class_counts'].get(class_id, 0))\n",
    "        val_counts.append(val_stats['class_counts'].get(class_id, 0))\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Class': classes,\n",
    "        'Train': train_counts,\n",
    "        'Val': val_counts,\n",
    "        'Total': [t + v for t, v in zip(train_counts, val_counts)]\n",
    "    })\n",
    "    \n",
    "    # Sort by total count\n",
    "    df = df.sort_values('Total', ascending=False)\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "    \n",
    "    # Plot 1: Bar chart\n",
    "    x = range(len(df))\n",
    "    width = 0.35\n",
    "    \n",
    "    axes[0].bar([i - width/2 for i in x], df['Train'], width, label='Train', alpha=0.8)\n",
    "    axes[0].bar([i + width/2 for i in x], df['Val'], width, label='Val', alpha=0.8)\n",
    "    axes[0].set_xlabel('Class')\n",
    "    axes[0].set_ylabel('Instance Count')\n",
    "    axes[0].set_title('Class Distribution (Train vs Val)', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xticks(x)\n",
    "    axes[0].set_xticklabels(df['Class'], rotation=45, ha='right')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Class imbalance ratio\n",
    "    max_count = df['Total'].max()\n",
    "    df['Imbalance_Ratio'] = max_count / df['Total']\n",
    "    \n",
    "    colors = ['green' if r < 2 else 'orange' if r < 5 else 'red' for r in df['Imbalance_Ratio']]\n",
    "    axes[1].barh(df['Class'], df['Imbalance_Ratio'], color=colors, alpha=0.7)\n",
    "    axes[1].set_xlabel('Imbalance Ratio (max_count / class_count)')\n",
    "    axes[1].set_ylabel('Class')\n",
    "    axes[1].set_title('Class Imbalance Analysis', fontsize=14, fontweight='bold')\n",
    "    axes[1].axvline(x=2, color='green', linestyle='--', label='Balanced (< 2:1)', alpha=0.5)\n",
    "    axes[1].axvline(x=5, color='orange', linestyle='--', label='Moderate (< 5:1)', alpha=0.5)\n",
    "    axes[1].axvline(x=10, color='red', linestyle='--', label='Severe (> 10:1)', alpha=0.5)\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_dir / 'dataset_distribution.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary table\n",
    "    print(\"\\nClass Distribution Summary:\")\n",
    "    print(\"=\" * 70)\n",
    "    print(df.to_string(index=False))\n",
    "    print(\"\\nImbalance Analysis:\")\n",
    "    print(f\"  Most common class: {df.iloc[0]['Class']} ({df.iloc[0]['Total']} instances)\")\n",
    "    print(f\"  Least common class: {df.iloc[-1]['Class']} ({df.iloc[-1]['Total']} instances)\")\n",
    "    print(f\"  Max imbalance ratio: {df['Imbalance_Ratio'].max():.2f}:1\")\n",
    "    print(f\"  Classes with severe imbalance (>10:1): {len(df[df['Imbalance_Ratio'] > 10])}\")\n",
    "\n",
    "# Visualize\n",
    "visualize_class_distribution(train_stats, val_stats, data_config['names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Configuration\n",
    "\n",
    "Based on best practices from:\n",
    "- SH17 paper (70.9% mAP with YOLOv9-e)\n",
    "- Model Zoo learnings (specialized models work well)\n",
    "- Edge deployment requirements (Hailo-8 on Raspberry Pi 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# TRAINING CONFIGURATION\n",
    "# ============================================\n",
    "\n",
    "# Model selection\n",
    "MODEL_VARIANT = 'yolov8n'  # Options: yolov8n, yolov8s, yolov8m, yolov9c\n",
    "# Note: yolov8n is fastest for edge deployment\n",
    "#       yolov9c gives ~3-5% better accuracy but test Hailo compatibility first\n",
    "\n",
    "# Training parameters (based on SH17 paper)\n",
    "training_config = {\n",
    "    # Dataset\n",
    "    'data': str(data_yaml_path),\n",
    "    \n",
    "    # Model architecture\n",
    "    'model': f'{MODEL_VARIANT}.pt',  # Use pretrained weights (transfer learning)\n",
    "    \n",
    "    # Training duration\n",
    "    'epochs': 150,  # SH17 used 200, we use 150 (good balance)\n",
    "    'patience': 30,  # Early stopping patience\n",
    "    \n",
    "    # Batch size (adjust based on GPU memory)\n",
    "    'batch': 16,  # Increase if you have more VRAM (32, 64, 128)\n",
    "    \n",
    "    # Image size\n",
    "    'imgsz': 640,  # SH17 validated this works well\n",
    "    \n",
    "    # Hardware\n",
    "    'device': 0 if torch.cuda.is_available() else 'cpu',\n",
    "    'workers': 8,  # Data loading workers\n",
    "    \n",
    "    # Output\n",
    "    'project': str(results_dir),\n",
    "    'name': f'deployment_{MODEL_VARIANT}_v1',\n",
    "    'exist_ok': True,\n",
    "    'save': True,\n",
    "    'save_period': 10,  # Save checkpoint every 10 epochs\n",
    "    \n",
    "    # Optimization\n",
    "    'optimizer': 'AdamW',  # Better than SGD for most cases\n",
    "    'lr0': 0.01,  # Initial learning rate\n",
    "    'lrf': 0.01,  # Final learning rate (fraction of lr0)\n",
    "    'momentum': 0.937,\n",
    "    'weight_decay': 0.0005,\n",
    "    'warmup_epochs': 3.0,\n",
    "    'warmup_momentum': 0.8,\n",
    "    'warmup_bias_lr': 0.1,\n",
    "    \n",
    "    # Loss weights\n",
    "    'box': 7.5,  # Box loss weight\n",
    "    'cls': 0.5,  # Classification loss weight\n",
    "    'dfl': 1.5,  # Distribution focal loss weight\n",
    "    \n",
    "    # Data Augmentation (SH17 paper validated)\n",
    "    'hsv_h': 0.015,  # HSV-Hue augmentation\n",
    "    'hsv_s': 0.7,    # HSV-Saturation augmentation\n",
    "    'hsv_v': 0.4,    # HSV-Value augmentation\n",
    "    'degrees': 0.0,  # Rotation (already done in Roboflow)\n",
    "    'translate': 0.1,  # Translation\n",
    "    'scale': 0.5,    # Scale augmentation\n",
    "    'shear': 0.0,    # Shear\n",
    "    'perspective': 0.0,  # Perspective\n",
    "    'flipud': 0.0,   # Vertical flip (not useful for overhead cameras)\n",
    "    'fliplr': 0.5,   # Horizontal flip (SH17 used this)\n",
    "    'mosaic': 1.0,   # Mosaic augmentation (SH17 used this)\n",
    "    'mixup': 0.0,    # MixUp augmentation\n",
    "    'copy_paste': 0.0,  # Copy-paste augmentation\n",
    "    \n",
    "    # Learning rate schedule\n",
    "    'cos_lr': True,  # Cosine learning rate scheduler\n",
    "    'close_mosaic': 10,  # Disable mosaic in last N epochs\n",
    "    \n",
    "    # Validation\n",
    "    'val': True,\n",
    "    'plots': True,  # Generate training plots\n",
    "    \n",
    "    # Advanced\n",
    "    'resume': False,  # Resume from checkpoint\n",
    "    'amp': True,  # Automatic Mixed Precision (faster training)\n",
    "    'fraction': 1.0,  # Train on fraction of dataset (1.0 = all)\n",
    "    'verbose': True,\n",
    "    'seed': 42,  # Random seed for reproducibility\n",
    "    'deterministic': True,  # Deterministic mode\n",
    "}\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Model: {training_config['model']}\")\n",
    "print(f\"Epochs: {training_config['epochs']}\")\n",
    "print(f\"Batch size: {training_config['batch']}\")\n",
    "print(f\"Image size: {training_config['imgsz']}\")\n",
    "print(f\"Device: {training_config['device']}\")\n",
    "print(f\"Optimizer: {training_config['optimizer']}\")\n",
    "print(f\"Learning rate: {training_config['lr0']} â†’ {training_config['lr0'] * training_config['lrf']}\")\n",
    "print(f\"\\nAugmentation:\")\n",
    "print(f\"  Mosaic: {training_config['mosaic']}\")\n",
    "print(f\"  Horizontal flip: {training_config['fliplr']}\")\n",
    "print(f\"  HSV: H={training_config['hsv_h']}, S={training_config['hsv_s']}, V={training_config['hsv_v']}\")\n",
    "print(f\"\\nOutput: {training_config['project']}/{training_config['name']}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Execution\n",
    "\n",
    "**Expected Training Time:**\n",
    "- YOLOv8n: 4-6 hours (150 epochs)\n",
    "- YOLOv8s: 6-8 hours (150 epochs)\n",
    "- YOLOv9c: 8-12 hours (150 epochs)\n",
    "\n",
    "**Progress Monitoring:**\n",
    "- Training metrics displayed in real-time\n",
    "- Checkpoints saved every 10 epochs\n",
    "- Best model saved automatically (based on validation mAP)\n",
    "\n",
    "**What to Expect:**\n",
    "- Target mAP50: 65-75% (based on clean data from Model Zoo)\n",
    "- Person, face, head, hand: 80-85% mAP (high-frequency classes)\n",
    "- Hardhat, safetyvest, shoes: 65-75% mAP (medium-frequency)\n",
    "- Gloves, facemask: 50-60% mAP (minority classes)\n",
    "- Glasses: 40-50% mAP (tiny objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "print(f\"Loading pretrained model: {training_config['model']}\")\n",
    "model = YOLO(training_config['model'])\n",
    "\n",
    "print(f\"\\nâœ“ Model loaded successfully\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.model.parameters())/1e6:.2f}M\")\n",
    "print(f\"Pretrained on: MS-COCO dataset\")\n",
    "print(f\"Transfer learning: Enabled âœ“\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Expected duration: 4-6 hours (for YOLOv8n)\")\n",
    "print(\"\\nYou can monitor progress in real-time below.\")\n",
    "print(\"Training can be safely interrupted (Ctrl+C) and resumed later.\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\")\n",
    "\n",
    "# Train the model\n",
    "try:\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    results = model.train(**training_config)\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    duration = (end_time - start_time).total_seconds() / 3600  # Hours\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"TRAINING COMPLETE!\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"End time: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Total duration: {duration:.2f} hours\")\n",
    "    print(f\"\\nBest weights saved to:\")\n",
    "    print(f\"  {results_dir / training_config['name'] / 'weights' / 'best.pt'}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\nâš ï¸  Training interrupted by user!\")\n",
    "    print(\"Checkpoint saved. You can resume training by setting 'resume': True in config.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n\\nâŒ Training failed with error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display training results\n",
    "results_path = results_dir / training_config['name']\n",
    "results_csv = results_path / 'results.csv'\n",
    "\n",
    "if results_csv.exists():\n",
    "    # Read results\n",
    "    results_df = pd.read_csv(results_csv)\n",
    "    results_df.columns = results_df.columns.str.strip()  # Remove whitespace\n",
    "    \n",
    "    print(\"Training Results Summary:\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Get final metrics\n",
    "    final_metrics = results_df.iloc[-1]\n",
    "    \n",
    "    print(f\"\\nFinal Epoch: {int(final_metrics['epoch'])}\")\n",
    "    print(f\"\\nValidation Metrics:\")\n",
    "    print(f\"  mAP50:     {final_metrics['metrics/mAP50(B)']:.4f}\")\n",
    "    print(f\"  mAP50-95:  {final_metrics['metrics/mAP50-95(B)']:.4f}\")\n",
    "    print(f\"  Precision: {final_metrics['metrics/precision(B)']:.4f}\")\n",
    "    print(f\"  Recall:    {final_metrics['metrics/recall(B)']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nTraining Losses (final):\")\n",
    "    print(f\"  Box loss:  {final_metrics['train/box_loss']:.4f}\")\n",
    "    print(f\"  Cls loss:  {final_metrics['train/cls_loss']:.4f}\")\n",
    "    print(f\"  DFL loss:  {final_metrics['train/dfl_loss']:.4f}\")\n",
    "    \n",
    "    # Find best epoch\n",
    "    best_epoch = results_df['metrics/mAP50(B)'].idxmax()\n",
    "    best_metrics = results_df.iloc[best_epoch]\n",
    "    \n",
    "    print(f\"\\nBest Epoch: {int(best_metrics['epoch'])}\")\n",
    "    print(f\"  mAP50:     {best_metrics['metrics/mAP50(B)']:.4f}\")\n",
    "    print(f\"  mAP50-95:  {best_metrics['metrics/mAP50-95(B)']:.4f}\")\n",
    "    print(f\"  Precision: {best_metrics['metrics/precision(B)']:.4f}\")\n",
    "    print(f\"  Recall:    {best_metrics['metrics/recall(B)']:.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "else:\n",
    "    print(\"âŒ Results file not found. Training may not have completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training curves\n",
    "if results_csv.exists():\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1: mAP curves\n",
    "    axes[0, 0].plot(results_df['epoch'], results_df['metrics/mAP50(B)'], label='mAP50', linewidth=2)\n",
    "    axes[0, 0].plot(results_df['epoch'], results_df['metrics/mAP50-95(B)'], label='mAP50-95', linewidth=2)\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('mAP')\n",
    "    axes[0, 0].set_title('Validation mAP', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Precision & Recall\n",
    "    axes[0, 1].plot(results_df['epoch'], results_df['metrics/precision(B)'], label='Precision', linewidth=2)\n",
    "    axes[0, 1].plot(results_df['epoch'], results_df['metrics/recall(B)'], label='Recall', linewidth=2)\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Value')\n",
    "    axes[0, 1].set_title('Precision & Recall', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Training losses\n",
    "    axes[1, 0].plot(results_df['epoch'], results_df['train/box_loss'], label='Box Loss', linewidth=2)\n",
    "    axes[1, 0].plot(results_df['epoch'], results_df['train/cls_loss'], label='Cls Loss', linewidth=2)\n",
    "    axes[1, 0].plot(results_df['epoch'], results_df['train/dfl_loss'], label='DFL Loss', linewidth=2)\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Loss')\n",
    "    axes[1, 0].set_title('Training Losses', fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Validation losses\n",
    "    axes[1, 1].plot(results_df['epoch'], results_df['val/box_loss'], label='Box Loss', linewidth=2)\n",
    "    axes[1, 1].plot(results_df['epoch'], results_df['val/cls_loss'], label='Cls Loss', linewidth=2)\n",
    "    axes[1, 1].plot(results_df['epoch'], results_df['val/dfl_loss'], label='DFL Loss', linewidth=2)\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Loss')\n",
    "    axes[1, 1].set_title('Validation Losses', fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_dir / 'training_curves.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nâœ“ Training curves saved to: {results_dir / 'training_curves.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Validation & Per-Class Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model for detailed validation\n",
    "best_model_path = results_path / 'weights' / 'best.pt'\n",
    "\n",
    "if best_model_path.exists():\n",
    "    print(f\"Loading best model from: {best_model_path}\")\n",
    "    best_model = YOLO(best_model_path)\n",
    "    \n",
    "    # Validate on test set\n",
    "    print(\"\\nRunning detailed validation...\")\n",
    "    val_results = best_model.val(\n",
    "        data=str(data_yaml_path),\n",
    "        batch=16,\n",
    "        imgsz=640,\n",
    "        device=0 if torch.cuda.is_available() else 'cpu',\n",
    "        plots=True,\n",
    "        save_json=True,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\nâœ“ Validation complete!\")\n",
    "else:\n",
    "    print(\"âŒ Best model not found. Training may not have completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze per-class performance\n",
    "if best_model_path.exists():\n",
    "    # Extract per-class metrics (from confusion matrix and validation results)\n",
    "    print(\"\\nPer-Class Performance Analysis:\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Check if confusion matrix exists\n",
    "    confusion_matrix_path = results_path / 'confusion_matrix.png'\n",
    "    if confusion_matrix_path.exists():\n",
    "        print(f\"\\nâœ“ Confusion matrix saved to: {confusion_matrix_path}\")\n",
    "        print(\"  Review this to identify which classes are being confused.\")\n",
    "    \n",
    "    # Check if per-class results exist\n",
    "    results_json_path = results_path / 'predictions.json'\n",
    "    if results_json_path.exists():\n",
    "        print(f\"\\nâœ“ Detailed predictions saved to: {results_json_path}\")\n",
    "    \n",
    "    print(\"\\nğŸ“Š Key Performance Indicators:\")\n",
    "    print(f\"  Overall mAP50: {val_results.box.map50:.4f}\")\n",
    "    print(f\"  Overall mAP50-95: {val_results.box.map:.4f}\")\n",
    "    print(f\"  Overall Precision: {val_results.box.mp:.4f}\")\n",
    "    print(f\"  Overall Recall: {val_results.box.mr:.4f}\")\n",
    "    \n",
    "    # Per-class mAP (if available)\n",
    "    if hasattr(val_results.box, 'maps'):\n",
    "        print(\"\\nğŸ“‹ Per-Class mAP50:\")\n",
    "        for idx, (class_name, map_value) in enumerate(zip((data_config['names'] if isinstance(data_config['names'], list) else list(data_config['names'].values())), val_results.box.maps)):\n",
    "            status = \"âœ“\" if map_value > 0.7 else \"âš ï¸\" if map_value > 0.5 else \"âŒ\"\n",
    "            print(f\"  {status} {class_name:15s}: {map_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Model for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to ONNX (required for Hailo conversion)\n",
    "if best_model_path.exists():\n",
    "    print(\"Exporting model to ONNX format...\")\n",
    "    print(\"This is required for Hailo HEF conversion.\")\n",
    "    print(\"\")\n",
    "    \n",
    "    try:\n",
    "        # Export to ONNX\n",
    "        onnx_path = best_model.export(\n",
    "            format='onnx',\n",
    "            imgsz=640,\n",
    "            simplify=True,\n",
    "            opset=11,  # Hailo-compatible opset\n",
    "            dynamic=False,  # Static shapes for Hailo\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nâœ“ ONNX export successful!\")\n",
    "        print(f\"  Saved to: {onnx_path}\")\n",
    "        print(f\"\\nğŸ“‹ Next steps:\")\n",
    "        print(f\"  1. Transfer ONNX file to machine with Hailo Dataflow Compiler\")\n",
    "        print(f\"  2. Convert to HEF using Hailo SDK:\")\n",
    "        print(f\"     hailo parser onnx {onnx_path} --hw-arch hailo8\")\n",
    "        print(f\"  3. Deploy HEF to Raspberry Pi + Hailo-8\")\n",
    "        \n",
    "        # Copy to models directory\n",
    "        import shutil\n",
    "        final_onnx_path = models_dir / f'deployment_{MODEL_VARIANT}_best.onnx'\n",
    "        shutil.copy(onnx_path, final_onnx_path)\n",
    "        print(f\"\\nâœ“ ONNX copied to: {final_onnx_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ ONNX export failed: {e}\")\n",
    "        print(\"You may need to export manually using the Ultralytics CLI.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Summary & Deployment Checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model summary\n",
    "if best_model_path.exists():\n",
    "    summary = {\n",
    "        'model': {\n",
    "            'variant': MODEL_VARIANT,\n",
    "            'architecture': 'YOLOv8' if 'yolov8' in MODEL_VARIANT else 'YOLOv9',\n",
    "            'parameters': f\"{sum(p.numel() for p in best_model.model.parameters())/1e6:.2f}M\",\n",
    "            'input_size': '640Ã—640',\n",
    "        },\n",
    "        'training': {\n",
    "            'epochs_trained': int(final_metrics['epoch']),\n",
    "            'best_epoch': int(best_metrics['epoch']),\n",
    "            'duration_hours': duration,\n",
    "            'dataset_size': train_stats['total_images'] + val_stats['total_images'],\n",
    "        },\n",
    "        'performance': {\n",
    "            'mAP50': float(val_results.box.map50),\n",
    "            'mAP50-95': float(val_results.box.map),\n",
    "            'precision': float(val_results.box.mp),\n",
    "            'recall': float(val_results.box.mr),\n",
    "        },\n",
    "        'deployment': {\n",
    "            'pytorch_model': str(best_model_path),\n",
    "            'onnx_model': str(final_onnx_path) if 'final_onnx_path' in locals() else 'Not exported',\n",
    "            'target_hardware': 'Raspberry Pi 5 + Hailo-8',\n",
    "            'expected_fps': '12-15 FPS per camera (4 cameras)',\n",
    "        },\n",
    "        'metadata': {\n",
    "            'training_date': datetime.now().isoformat(),\n",
    "            'data_yaml': str(data_yaml_path),\n",
    "            'classes': list((data_config['names'] if isinstance(data_config['names'], list) else list(data_config['names'].values()))),\n",
    "            'num_classes': data_config['nc'],\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save summary\n",
    "    summary_path = models_dir / f'deployment_{MODEL_VARIANT}_summary.json'\n",
    "    with open(summary_path, 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"MODEL SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "    print(json.dumps(summary, indent=2))\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"âœ“ Summary saved to: {summary_path}\")\n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deployment checklist\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DEPLOYMENT CHECKLIST\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "checklist = [\n",
    "    (\"Training completed\", best_model_path.exists()),\n",
    "    (\"mAP50 > 0.65 (target)\", val_results.box.map50 > 0.65 if 'val_results' in locals() else False),\n",
    "    (\"ONNX export successful\", 'final_onnx_path' in locals()),\n",
    "    (\"Model summary saved\", summary_path.exists() if 'summary_path' in locals() else False),\n",
    "]\n",
    "\n",
    "for task, completed in checklist:\n",
    "    status = \"âœ…\" if completed else \"âŒ\"\n",
    "    print(f\"{status} {task}\")\n",
    "\n",
    "print(\"\\nğŸ“‹ Next Steps:\")\n",
    "print(\"1. Convert ONNX to HEF using Hailo Dataflow Compiler\")\n",
    "print(\"2. Test HEF inference on Raspberry Pi + Hailo-8\")\n",
    "print(\"3. Integrate into SCM inference pipeline\")\n",
    "print(\"4. Multi-camera testing (4 streams)\")\n",
    "print(\"5. End-to-end validation with Rust runtime\")\n",
    "print(\"6. Deploy to production (Unilever + Pelindo)\")\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Performance Comparison with Expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with expected performance\n",
    "if 'val_results' in locals():\n",
    "    expected_performance = {\n",
    "        'Overall': {\n",
    "            'target': 0.70,\n",
    "            'minimum': 0.65,\n",
    "            'actual': float(val_results.box.map50)\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    print(\"\\nPerformance Evaluation:\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    actual_map = expected_performance['Overall']['actual']\n",
    "    target_map = expected_performance['Overall']['target']\n",
    "    minimum_map = expected_performance['Overall']['minimum']\n",
    "    \n",
    "    print(f\"\\nOverall mAP50:\")\n",
    "    print(f\"  Target:  {target_map:.2%} (SH17 paper benchmark)\")\n",
    "    print(f\"  Minimum: {minimum_map:.2%} (acceptable)\")\n",
    "    print(f\"  Actual:  {actual_map:.2%}\", end=\"\")\n",
    "    \n",
    "    if actual_map >= target_map:\n",
    "        print(\" âœ… EXCEEDS TARGET!\")\n",
    "        print(\"\\nğŸ‰ Excellent! Model performance exceeds expectations.\")\n",
    "    elif actual_map >= minimum_map:\n",
    "        print(\" âœ“ MEETS REQUIREMENTS\")\n",
    "        print(\"\\nâœ“ Good! Model performance is acceptable for deployment.\")\n",
    "    else:\n",
    "        print(\" âš ï¸ BELOW MINIMUM\")\n",
    "        print(\"\\nâš ï¸ Warning: Model performance below minimum threshold.\")\n",
    "        print(\"Consider:\")\n",
    "        print(\"  - Training for more epochs\")\n",
    "        print(\"  - Collecting more training data\")\n",
    "        print(\"  - Using larger model variant (yolov8s or yolov9c)\")\n",
    "        print(\"  - Reviewing data quality\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Final Notes & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                   DEPLOYMENT MODEL TRAINING COMPLETE                 â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "ğŸ“Š Training Results:\n",
    "   âœ“ Model trained successfully\n",
    "   âœ“ Validation metrics computed\n",
    "   âœ“ ONNX export completed\n",
    "   âœ“ Model summary saved\n",
    "\n",
    "ğŸ¯ Next Steps for Deployment:\n",
    "\n",
    "   1. HEF Conversion (Hailo Dataflow Compiler)\n",
    "      â””â”€ Convert ONNX â†’ HEF for Hailo-8 deployment\n",
    "   \n",
    "   2. Edge Device Testing\n",
    "      â””â”€ Test HEF inference on Raspberry Pi 5 + Hailo-8\n",
    "   \n",
    "   3. Pipeline Integration\n",
    "      â””â”€ Integrate model into SCM inference engine\n",
    "   \n",
    "   4. Multi-Camera Validation\n",
    "      â””â”€ Test with 4 RTSP camera streams simultaneously\n",
    "   \n",
    "   5. End-to-End Testing\n",
    "      â””â”€ Validate full system: Detection â†’ Rust â†’ iOS\n",
    "   \n",
    "   6. Production Deployment\n",
    "      â””â”€ Deploy to Unilever + Pelindo facilities\n",
    "\n",
    "ğŸ“ Important Files:\n",
    "\"\"\")\n",
    "\n",
    "if best_model_path.exists():\n",
    "    print(f\"   PyTorch Model:  {best_model_path}\")\n",
    "if 'final_onnx_path' in locals():\n",
    "    print(f\"   ONNX Model:     {final_onnx_path}\")\n",
    "if 'summary_path' in locals():\n",
    "    print(f\"   Model Summary:  {summary_path}\")\n",
    "print(f\"   Training Logs:  {results_path}\")\n",
    "\n",
    "print(\"\"\"\n",
    "ğŸ’¡ Performance Tips:\n",
    "   â€¢ Model performance may improve with real-world data flywheel\n",
    "   â€¢ Monitor false positive/negative rates in production\n",
    "   â€¢ Collect edge cases for model v2 training\n",
    "   â€¢ Consider per-facility fine-tuning if needed\n",
    "\n",
    "ğŸš€ You're ready to proceed to deployment!\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
