{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Zoo Training - Specialized PPE Detectors\n",
    "\n",
    "**Project:** Safety Compliance Monitoring (SCM)\n",
    "\n",
    "**Date:** January 2026\n",
    "\n",
    "**Objective:** Train specialized single-class detectors for Model Zoo approach\n",
    "- Each model detects ONE class only (binary: object vs background)\n",
    "- No class imbalance issues!\n",
    "- Better bbox quality per class\n",
    "- Faster iteration and improvement\n",
    "\n",
    "**Usage:**\n",
    "- Auto-labeling: Use all models together (high quality)\n",
    "- Deployment: Train single model on clean data from Model Zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install ultralytics roboflow opencv-python matplotlib seaborn pandas\n",
    "\n",
    "import ultralytics\n",
    "print(f\"Ultralytics version: {ultralytics.__version__}\")\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up directories\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "base_dir = Path.home() / 'optense' / 'scm'\n",
    "models_dir = base_dir / 'models' / 'zoo'\n",
    "datasets_dir = base_dir / 'datasets' / 'zoo'\n",
    "results_dir = base_dir / 'training_results' / 'model_zoo'\n",
    "\n",
    "for dir_path in [models_dir, datasets_dir, results_dir]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"✓ Base directory: {base_dir}\")\n",
    "print(f\"✓ Models will be saved to: {models_dir}\")\n",
    "print(f\"✓ Training results: {results_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Zoo Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ROBOFLOW CONFIGURATION\n",
    "# ============================================\n",
    "\n",
    "ROBOFLOW_API_KEY = \"Xp2CBnbQfijsteBmE2Op\"  # From: https://app.roboflow.com/settings/api\n",
    "WORKSPACE_NAME = \"optense\"\n",
    "\n",
    "# ============================================\n",
    "# MODEL ZOO CONFIGURATION\n",
    "# ============================================\n",
    "\n",
    "MODEL_CONFIGS = {\n",
    "    # # Priority 1: Foundation model\n",
    "    # 'person': {\n",
    "    #     'project': 'aa-person',\n",
    "    #     'version': 1,\n",
    "    #     'epochs': 100,\n",
    "    #     'batch': 16,\n",
    "    #     'patience': 15,\n",
    "    #     'conf_threshold': 0.30,  # For inference/auto-labeling\n",
    "    #     'priority': 1,\n",
    "    #     'description': 'Detect persons - foundation for all PPE checks',\n",
    "    # },\n",
    "    # 'head': {\n",
    "    #     'project': 'aa-head',\n",
    "    #     'version': 1,\n",
    "    #     'epochs': 100,\n",
    "    #     'batch': 16,\n",
    "    #     'patience': 15,\n",
    "    #     'conf_threshold': 0.30,  # For inference/auto-labeling\n",
    "    #     'priority': 1,\n",
    "    #     'description': 'Detect heads - foundation for all PPE checks',\n",
    "    # },\n",
    "    # 'hand': {\n",
    "    #     'project': 'aa-hand',\n",
    "    #     'version': 1,\n",
    "    #     'epochs': 100,\n",
    "    #     'batch': 16,\n",
    "    #     'patience': 15,\n",
    "    #     'conf_threshold': 0.30,  # For inference/auto-labeling\n",
    "    #     'priority': 1,\n",
    "    #     'description': 'Detect hands - foundation for all PPE checks',\n",
    "    # },\n",
    "    # 'face': {\n",
    "    #     'project': 'aa-face',\n",
    "    #     'version': 3,\n",
    "    #     'epochs': 100,\n",
    "    #     'batch': 16,\n",
    "    #     'patience': 15,\n",
    "    #     'conf_threshold': 0.30,  # For inference/auto-labeling\n",
    "    #     'priority': 1,\n",
    "    #     'description': 'Detect faces - foundation for all PPE checks',\n",
    "    # },\n",
    "    \n",
    "    # # Priority 2: Common critical PPE\n",
    "    # 'hardhat': {\n",
    "    #     'project': 'aa-hardhat',\n",
    "    #     'version': 3,\n",
    "    #     'epochs': 100,\n",
    "    #     'batch': 16,\n",
    "    #     'patience': 15,\n",
    "    #     'conf_threshold': 0.40,\n",
    "    #     'priority': 2,\n",
    "    #     'description': 'Detect hardhats - critical PPE',\n",
    "    # },\n",
    "    \n",
    "    # 'gloves': {\n",
    "    #     'project': 'aa-gloves',\n",
    "    #     'version': 2,\n",
    "    #     'epochs': 100,\n",
    "    #     'batch': 16,\n",
    "    #     'patience': 15,\n",
    "    #     'conf_threshold': 0.35,\n",
    "    #     'priority': 2,\n",
    "    #     'description': 'Detect gloves - critical PPE',\n",
    "    # },\n",
    "    \n",
    "    # 'shoes': {\n",
    "    #     'project': 'aa-shoes',\n",
    "    #     'version': 2,\n",
    "    #     'epochs': 100,\n",
    "    #     'batch': 16,\n",
    "    #     'patience': 15,\n",
    "    #     'conf_threshold': 0.40,\n",
    "    #     'priority': 2,\n",
    "    #     'description': 'Detect safety shoes - critical PPE',\n",
    "    # },\n",
    "    \n",
    "    # Priority 3: Medium-frequency PPE\n",
    "    # 'safetyvest': {\n",
    "    #     'project': 'aa-safetyvest',\n",
    "    #     'version': 4,\n",
    "    #     'epochs': 120,  # Slightly more for medium-frequency\n",
    "    #     'batch': 16,\n",
    "    #     'patience': 15,\n",
    "    #     'conf_threshold': 0.35,\n",
    "    #     'priority': 3,\n",
    "    #     'description': 'Detect safety vests',\n",
    "    # },\n",
    "    # 'safetysuit': {\n",
    "    #     'project': 'aa-safetysuit',\n",
    "    #     'version': 4,\n",
    "    #     'epochs': 120,  # Slightly more for medium-frequency\n",
    "    #     'batch': 16,\n",
    "    #     'patience': 15,\n",
    "    #     'conf_threshold': 0.35,\n",
    "    #     'priority': 3,\n",
    "    #     'description': 'Detect safety suits',\n",
    "    # },\n",
    "    'glasses': {\n",
    "        'project': 'aa-glasses',\n",
    "        'version': 2,\n",
    "        'epochs': 120,  # Slightly more for medium-frequency\n",
    "        'batch': 16,\n",
    "        'patience': 15,\n",
    "        'conf_threshold': 0.35,\n",
    "        'priority': 3,\n",
    "        'description': 'Detect glasses',\n",
    "    },\n",
    "    'facemask': {\n",
    "        'project': 'aa-facemask',\n",
    "        'version': 1,\n",
    "        'epochs': 120,  # Slightly more for medium-frequency\n",
    "        'batch': 16,\n",
    "        'patience': 15,\n",
    "        'conf_threshold': 0.35,\n",
    "        'priority': 3,\n",
    "        'description': 'Detect facemasks',\n",
    "    },\n",
    "    \n",
    "    # # Priority 4: Rare\n",
    "    # 'foot': {\n",
    "    #     'project': 'aa-foot',\n",
    "    #     'version': 2,\n",
    "    #     'epochs': 150,  # More epochs for rare class\n",
    "    #     'batch': 16,\n",
    "    #     'patience': 20,  # More patience for rare class\n",
    "    #     'conf_threshold': 0.25,  # Lower threshold (rare = harder to detect)\n",
    "    #     'priority': 4,\n",
    "    #     'description': 'Detect foot - rare class',\n",
    "    # },\n",
    "}\n",
    "\n",
    "# Training order (by priority)\n",
    "TRAINING_ORDER = sorted(\n",
    "    MODEL_CONFIGS.keys(),\n",
    "    key=lambda x: MODEL_CONFIGS[x]['priority']\n",
    ")\n",
    "\n",
    "print(\"Model Zoo Configuration:\")\n",
    "print(f\"  Total models: {len(MODEL_CONFIGS)}\")\n",
    "print(f\"  Training order: {TRAINING_ORDER}\")\n",
    "print(\"\\nModels to train:\")\n",
    "for i, class_name in enumerate(TRAINING_ORDER, 1):\n",
    "    config = MODEL_CONFIGS[class_name]\n",
    "    print(f\"  {i}. {class_name:12s} - {config['description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download Datasets from Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "\n",
    "# Initialize Roboflow\n",
    "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
    "print(\"✓ Roboflow initialized\")\n",
    "\n",
    "# Download all datasets\n",
    "downloaded_datasets = {}\n",
    "\n",
    "for class_name in TRAINING_ORDER:\n",
    "    config = MODEL_CONFIGS[class_name]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Downloading: {class_name} dataset\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Project: {config['project']}\")\n",
    "    print(f\"Version: {config['version']}\")\n",
    "    \n",
    "    try:\n",
    "        project = rf.workspace(WORKSPACE_NAME).project(config['project'])\n",
    "        dataset = project.version(config['version']).download(\n",
    "            'yolov8',\n",
    "            location=str(datasets_dir / class_name)\n",
    "        )\n",
    "        \n",
    "        downloaded_datasets[class_name] = {\n",
    "            'location': dataset.location,\n",
    "            'data_yaml': Path(dataset.location) / 'data.yaml'\n",
    "        }\n",
    "        \n",
    "        print(f\"✓ Downloaded to: {dataset.location}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error downloading {class_name}: {e}\")\n",
    "        print(f\"   Skipping this model...\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Downloaded {len(downloaded_datasets)}/{len(MODEL_CONFIGS)} datasets\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inspect Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def inspect_single_class_dataset(data_yaml_path, class_name):\n",
    "    \"\"\"Inspect single-class dataset.\"\"\"\n",
    "    \n",
    "    with open(data_yaml_path, 'r') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    \n",
    "    dataset_root = Path(data_yaml_path).parent\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Dataset: {class_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Classes: {data['nc']} ({data['names']})\")\n",
    "    \n",
    "    # Count images\n",
    "    train_images = list((dataset_root / data['train']).glob('*.jpg')) + \\\n",
    "                   list((dataset_root / data['train']).glob('*.png'))\n",
    "    val_images = list((dataset_root / data['val']).glob('*.jpg')) + \\\n",
    "                 list((dataset_root / data['val']).glob('*.png'))\n",
    "    \n",
    "    print(f\"\\nImage counts:\")\n",
    "    print(f\"  Train: {len(train_images)}\")\n",
    "    print(f\"  Val: {len(val_images)}\")\n",
    "    print(f\"  Total: {len(train_images) + len(val_images)}\")\n",
    "    \n",
    "    # Count positive vs negative samples\n",
    "    train_labels_dir = dataset_root / data['train'].replace('images', 'labels')\n",
    "    \n",
    "    positive_samples = 0\n",
    "    negative_samples = 0\n",
    "    total_annotations = 0\n",
    "    \n",
    "    for img_file in train_images:\n",
    "        label_file = train_labels_dir / f\"{img_file.stem}.txt\"\n",
    "        \n",
    "        if label_file.exists():\n",
    "            with open(label_file) as f:\n",
    "                lines = f.readlines()\n",
    "                if lines:\n",
    "                    positive_samples += 1\n",
    "                    total_annotations += len(lines)\n",
    "                else:\n",
    "                    negative_samples += 1\n",
    "        else:\n",
    "            negative_samples += 1\n",
    "    \n",
    "    print(f\"\\nAnnotation breakdown:\")\n",
    "    print(f\"  Positive samples: {positive_samples} (images with {class_name})\")\n",
    "    print(f\"  Negative samples: {negative_samples} (images without {class_name})\")\n",
    "    print(f\"  Total annotations: {total_annotations}\")\n",
    "    \n",
    "    if positive_samples > 0:\n",
    "        ratio = negative_samples / positive_samples\n",
    "        print(f\"  Negative:Positive ratio: {ratio:.2f}:1\")\n",
    "    \n",
    "    return {\n",
    "        'class_name': class_name,\n",
    "        'train_images': len(train_images),\n",
    "        'val_images': len(val_images),\n",
    "        'positive_samples': positive_samples,\n",
    "        'negative_samples': negative_samples,\n",
    "        'total_annotations': total_annotations,\n",
    "    }\n",
    "\n",
    "# Inspect all datasets\n",
    "dataset_stats = {}\n",
    "\n",
    "for class_name, dataset_info in downloaded_datasets.items():\n",
    "    stats = inspect_single_class_dataset(\n",
    "        dataset_info['data_yaml'],\n",
    "        class_name\n",
    "    )\n",
    "    dataset_stats[class_name] = stats\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Dataset Inspection Complete\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize dataset statistics\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(dataset_stats).T\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Total images per class\n",
    "df['total_images'] = df['train_images'] + df['val_images']\n",
    "df['total_images'].plot(kind='bar', ax=axes[0, 0], color='steelblue')\n",
    "axes[0, 0].set_title('Total Images per Class')\n",
    "axes[0, 0].set_ylabel('Image Count')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot 2: Positive vs Negative samples\n",
    "df[['positive_samples', 'negative_samples']].plot(kind='bar', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Positive vs Negative Samples')\n",
    "axes[0, 1].set_ylabel('Sample Count')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "axes[0, 1].legend(['Positive', 'Negative'])\n",
    "\n",
    "# Plot 3: Total annotations\n",
    "df['total_annotations'].plot(kind='bar', ax=axes[1, 0], color='coral')\n",
    "axes[1, 0].set_title('Total Annotations per Class')\n",
    "axes[1, 0].set_ylabel('Annotation Count')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot 4: Negative:Positive ratio\n",
    "df['ratio'] = df['negative_samples'] / df['positive_samples']\n",
    "df['ratio'].plot(kind='bar', ax=axes[1, 1], color='lightgreen')\n",
    "axes[1, 1].set_title('Negative:Positive Ratio')\n",
    "axes[1, 1].set_ylabel('Ratio')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "axes[1, 1].axhline(y=1, color='r', linestyle='--', label='Balanced (1:1)')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(results_dir / 'dataset_statistics.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ Statistics saved to: {results_dir / 'dataset_statistics.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_config(class_name, data_yaml_path):\n",
    "    \"\"\"\n",
    "    Get training configuration for specific class.\n",
    "    \"\"\"\n",
    "    \n",
    "    config = MODEL_CONFIGS[class_name]\n",
    "    \n",
    "    training_config = {\n",
    "        'data': str(data_yaml_path),\n",
    "        'epochs': config['epochs'],\n",
    "        'batch': config['batch'],\n",
    "        'imgsz': 640,\n",
    "        'patience': config['patience'],\n",
    "        'save': True,\n",
    "        'save_period': 10,\n",
    "        'device': 0 if torch.cuda.is_available() else 'cpu',\n",
    "        'workers': 8,\n",
    "        'project': str(results_dir),\n",
    "        'name': f'{class_name}_v1',\n",
    "        'exist_ok': True,\n",
    "        'pretrained': True,\n",
    "        'optimizer': 'AdamW',\n",
    "        'verbose': True,\n",
    "        'seed': 42,\n",
    "        'single_cls': True,  # CRITICAL: Binary classification mode!\n",
    "        \n",
    "        # Learning rates\n",
    "        'lr0': 0.01,\n",
    "        'lrf': 0.01,\n",
    "        'momentum': 0.937,\n",
    "        'weight_decay': 0.0005,\n",
    "        'warmup_epochs': 3.0,\n",
    "        'warmup_momentum': 0.8,\n",
    "        'warmup_bias_lr': 0.1,\n",
    "        \n",
    "        # Loss weights\n",
    "        'box': 7.5,\n",
    "        'cls': 0.5,\n",
    "        'dfl': 1.5,\n",
    "        \n",
    "        # Augmentation (already done in Roboflow, but add some)\n",
    "        'hsv_h': 0.015,\n",
    "        'hsv_s': 0.7,\n",
    "        'hsv_v': 0.4,\n",
    "        'degrees': 0.0,  # Rotation done in Roboflow\n",
    "        'translate': 0.1,\n",
    "        'scale': 0.5,\n",
    "        'shear': 0.0,\n",
    "        'perspective': 0.0,\n",
    "        'flipud': 0.0,\n",
    "        'fliplr': 0.5,\n",
    "        'mosaic': 1.0,\n",
    "        'mixup': 0.0,\n",
    "        'copy_paste': 0.0,\n",
    "        \n",
    "        # Validation\n",
    "        'cos_lr': True,\n",
    "        'close_mosaic': 10,\n",
    "        'resume': False,\n",
    "        'amp': True,\n",
    "        'fraction': 1.0,\n",
    "        'plots': True,\n",
    "        'val': True,\n",
    "    }\n",
    "    \n",
    "    return training_config\n",
    "\n",
    "print(\"✓ Training configuration ready\")\n",
    "print(f\"  Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(f\"  Single-class mode: Enabled\")\n",
    "print(f\"  Batch size: {MODEL_CONFIGS[TRAINING_ORDER[0]]['batch']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training tracker\n",
    "training_results = {}\n",
    "training_log = []\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STARTING MODEL ZOO TRAINING\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Models to train: {len(downloaded_datasets)}\")\n",
    "print(f\"Estimated time: {len(downloaded_datasets) * 45} minutes ({len(downloaded_datasets) * 0.75:.1f} hours)\")\n",
    "print(f\"Training order: {' → '.join(TRAINING_ORDER)}\")\n",
    "print(\"\")\n",
    "print(\"You can monitor progress in real-time!\")\n",
    "print(\"Each model takes ~30-60 minutes depending on dataset size.\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for idx, class_name in enumerate(TRAINING_ORDER, 1):\n",
    "    if class_name not in downloaded_datasets:\n",
    "        print(f\"\\n⚠️  Skipping {class_name} (dataset not downloaded)\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n\\n{'='*70}\")\n",
    "    print(f\"TRAINING MODEL {idx}/{len(downloaded_datasets)}: {class_name.upper()}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    config = MODEL_CONFIGS[class_name]\n",
    "    dataset_info = downloaded_datasets[class_name]\n",
    "    \n",
    "    print(f\"Description: {config['description']}\")\n",
    "    print(f\"Priority: {config['priority']}\")\n",
    "    print(f\"Epochs: {config['epochs']}\")\n",
    "    print(f\"Confidence threshold (for inference): {config['conf_threshold']}\")\n",
    "    print(f\"Dataset: {dataset_stats[class_name]['train_images']} train, {dataset_stats[class_name]['val_images']} val\")\n",
    "    print(f\"Positive samples: {dataset_stats[class_name]['positive_samples']}\")\n",
    "    print(\"\")\n",
    "    \n",
    "    model_start = datetime.now()\n",
    "    \n",
    "    try:\n",
    "        # Initialize model\n",
    "        model = YOLO('yolov8n.pt')\n",
    "        \n",
    "        # Get training config\n",
    "        train_config = get_training_config(class_name, dataset_info['data_yaml'])\n",
    "        \n",
    "        # Train\n",
    "        print(f\"Starting training for {class_name}...\\n\")\n",
    "        results = model.train(**train_config)\n",
    "        \n",
    "        model_end = datetime.now()\n",
    "        duration = (model_end - model_start).total_seconds() / 60\n",
    "        \n",
    "        # Extract metrics\n",
    "        try:\n",
    "            final_metrics = {\n",
    "                'mAP50': float(results.results_dict.get('metrics/mAP50(B)', 0)),\n",
    "                'mAP50-95': float(results.results_dict.get('metrics/mAP50-95(B)', 0)),\n",
    "                'precision': float(results.results_dict.get('metrics/precision(B)', 0)),\n",
    "                'recall': float(results.results_dict.get('metrics/recall(B)', 0)),\n",
    "            }\n",
    "        except:\n",
    "            # Fallback if metrics not available\n",
    "            final_metrics = {\n",
    "                'mAP50': 0.0,\n",
    "                'mAP50-95': 0.0,\n",
    "                'precision': 0.0,\n",
    "                'recall': 0.0,\n",
    "            }\n",
    "        \n",
    "        # Find best weights\n",
    "        best_weights = list((results_dir / f'{class_name}_v1').glob('**/weights/best.pt'))[0]\n",
    "        \n",
    "        # Save to model zoo\n",
    "        model_save_path = models_dir / f'{class_name}_v1.pt'\n",
    "        shutil.copy(best_weights, model_save_path)\n",
    "        \n",
    "        # Save metadata\n",
    "        metadata = {\n",
    "            'class': class_name,\n",
    "            'version': 'v1',\n",
    "            'trained_at': datetime.now().isoformat(),\n",
    "            'duration_minutes': round(duration, 1),\n",
    "            'metrics': final_metrics,\n",
    "            'conf_threshold': config['conf_threshold'],\n",
    "            'dataset': {\n",
    "                'project': config['project'],\n",
    "                'version': config['version'],\n",
    "                'train_images': dataset_stats[class_name]['train_images'],\n",
    "                'positive_samples': dataset_stats[class_name]['positive_samples'],\n",
    "            },\n",
    "            'training_config': {\n",
    "                'epochs': config['epochs'],\n",
    "                'batch': config['batch'],\n",
    "                'patience': config['patience'],\n",
    "            },\n",
    "        }\n",
    "        \n",
    "        with open(model_save_path.with_suffix('.json'), 'w') as f:\n",
    "            json.dump(metadata, f, indent=2)\n",
    "        \n",
    "        training_results[class_name] = {\n",
    "            'status': 'success',\n",
    "            'metrics': final_metrics,\n",
    "            'duration': duration,\n",
    "            'model_path': str(model_save_path),\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"✓ {class_name.upper()} TRAINING COMPLETE!\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Duration: {duration:.1f} minutes\")\n",
    "        print(f\"mAP50: {final_metrics['mAP50']:.4f}\")\n",
    "        print(f\"mAP50-95: {final_metrics['mAP50-95']:.4f}\")\n",
    "        print(f\"Precision: {final_metrics['precision']:.4f}\")\n",
    "        print(f\"Recall: {final_metrics['recall']:.4f}\")\n",
    "        print(f\"Model saved: {model_save_path}\")\n",
    "        print(f\"Metadata saved: {model_save_path.with_suffix('.json')}\")\n",
    "        \n",
    "        # Log\n",
    "        log_entry = f\"[{datetime.now().strftime('%H:%M:%S')}] ✓ {class_name}: mAP50={final_metrics['mAP50']:.3f}, {duration:.1f}min\"\n",
    "        training_log.append(log_entry)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ ERROR training {class_name}: {e}\")\n",
    "        training_results[class_name] = {\n",
    "            'status': 'failed',\n",
    "            'error': str(e),\n",
    "        }\n",
    "        log_entry = f\"[{datetime.now().strftime('%H:%M:%S')}] ❌ {class_name}: FAILED - {e}\"\n",
    "        training_log.append(log_entry)\n",
    "\n",
    "end_time = datetime.now()\n",
    "total_duration = (end_time - start_time).total_seconds() / 60\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*70)\n",
    "print(\"MODEL ZOO TRAINING COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total time: {total_duration:.1f} minutes ({total_duration/60:.1f} hours)\")\n",
    "print(f\"Models trained: {sum(1 for r in training_results.values() if r['status'] == 'success')}/{len(downloaded_datasets)}\")\n",
    "print(f\"Models saved in: {models_dir}\")\n",
    "print(\"\\nTraining log:\")\n",
    "for entry in training_log:\n",
    "    print(f\"  {entry}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results summary\n",
    "summary_data = []\n",
    "\n",
    "for class_name in TRAINING_ORDER:\n",
    "    if class_name in training_results and training_results[class_name]['status'] == 'success':\n",
    "        result = training_results[class_name]\n",
    "        summary_data.append({\n",
    "            'Class': class_name,\n",
    "            'mAP50': result['metrics']['mAP50'],\n",
    "            'mAP50-95': result['metrics']['mAP50-95'],\n",
    "            'Precision': result['metrics']['precision'],\n",
    "            'Recall': result['metrics']['recall'],\n",
    "            'Duration (min)': result['duration'],\n",
    "            'Train Samples': dataset_stats[class_name]['positive_samples'],\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL ZOO RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "results_csv = results_dir / 'model_zoo_results.csv'\n",
    "results_df.to_csv(results_csv, index=False)\n",
    "print(f\"\\n✓ Results saved to: {results_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: mAP50 per model\n",
    "results_df.plot(x='Class', y='mAP50', kind='bar', ax=axes[0, 0], color='steelblue', legend=False)\n",
    "axes[0, 0].set_title('mAP50 per Model', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('mAP50')\n",
    "axes[0, 0].set_xlabel('')\n",
    "axes[0, 0].axhline(y=0.6, color='g', linestyle='--', label='Good (0.6)')\n",
    "axes[0, 0].axhline(y=0.4, color='orange', linestyle='--', label='Acceptable (0.4)')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot 2: Precision vs Recall\n",
    "axes[0, 1].scatter(results_df['Recall'], results_df['Precision'], s=100, alpha=0.6)\n",
    "for idx, row in results_df.iterrows():\n",
    "    axes[0, 1].annotate(row['Class'], (row['Recall'], row['Precision']), \n",
    "                       fontsize=8, ha='center')\n",
    "axes[0, 1].set_title('Precision vs Recall', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Recall')\n",
    "axes[0, 1].set_ylabel('Precision')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].set_xlim([0, 1])\n",
    "axes[0, 1].set_ylim([0, 1])\n",
    "\n",
    "# Plot 3: Training duration\n",
    "results_df.plot(x='Class', y='Duration (min)', kind='bar', ax=axes[1, 0], color='coral', legend=False)\n",
    "axes[1, 0].set_title('Training Duration', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Minutes')\n",
    "axes[1, 0].set_xlabel('')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot 4: mAP vs Dataset Size\n",
    "axes[1, 1].scatter(results_df['Train Samples'], results_df['mAP50'], s=100, alpha=0.6)\n",
    "for idx, row in results_df.iterrows():\n",
    "    axes[1, 1].annotate(row['Class'], (row['Train Samples'], row['mAP50']), \n",
    "                       fontsize=8, ha='center')\n",
    "axes[1, 1].set_title('mAP50 vs Dataset Size', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Training Samples (Positive)')\n",
    "axes[1, 1].set_ylabel('mAP50')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(results_dir / 'model_zoo_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"✓ Results visualization saved to: {results_dir / 'model_zoo_results.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Zoo Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model Zoo inventory\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL ZOO INVENTORY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Location: {models_dir}\")\n",
    "print(\"\\nAvailable models:\")\n",
    "\n",
    "zoo_inventory = []\n",
    "\n",
    "for model_file in sorted(models_dir.glob('*.pt')):\n",
    "    metadata_file = model_file.with_suffix('.json')\n",
    "    \n",
    "    if metadata_file.exists():\n",
    "        with open(metadata_file) as f:\n",
    "            metadata = json.load(f)\n",
    "        \n",
    "        print(f\"\\n  ✓ {metadata['class']:12s} (v{metadata['version'][1:]})\")\n",
    "        print(f\"    Model: {model_file.name}\")\n",
    "        print(f\"    mAP50: {metadata['metrics']['mAP50']:.3f}\")\n",
    "        print(f\"    Confidence threshold: {metadata['conf_threshold']}\")\n",
    "        print(f\"    Trained: {metadata['trained_at'][:10]}\")\n",
    "        print(f\"    Duration: {metadata['duration_minutes']:.1f} min\")\n",
    "        \n",
    "        zoo_inventory.append({\n",
    "            'class': metadata['class'],\n",
    "            'version': metadata['version'],\n",
    "            'model_path': str(model_file),\n",
    "            'metadata_path': str(metadata_file),\n",
    "            'mAP50': metadata['metrics']['mAP50'],\n",
    "            'conf_threshold': metadata['conf_threshold'],\n",
    "        })\n",
    "\n",
    "# Save inventory\n",
    "inventory_file = models_dir / 'zoo_inventory.json'\n",
    "with open(inventory_file, 'w') as f:\n",
    "    json.dump(zoo_inventory, f, indent=2)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Total models in zoo: {len(zoo_inventory)}\")\n",
    "print(f\"Inventory saved to: {inventory_file}\")\n",
    "print(f\"{'='*70}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
